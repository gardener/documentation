---
title: November 2025
weight: -202511
---

# Hack The Garden 11/2025 Wrap Up

- ğŸ—“ï¸ **Date:** 24.11.2025 â€“ 28.11.2025
- ğŸ“ **Location:** [Schlosshof Freizeitheim, Schelklingen](https://www.schlosshof-info.de/)
- ğŸ‘¤ **Organizer:** [x-cellent](https://www.x-cellent.com/)
- ğŸ“˜ **Topics:** https://hackmd.io/c-SxOnnDTE-XQbrXnrPprw
- ğŸ¤ **Review Meeting Summary:** https://gardener.cloud/community/review-meetings/2025-reviews/#_2025-12-03-hack-the-garden-wrap-up

![Group picture](./images/2025-11/group-picture.jpeg)

<hr />

## ğŸ¶ Use Self-Hosted Shoot Cluster For Single-Node E2E Tests

_TODO_

## ğŸ«† Enrich Shoot Logs with Istio Access Logs

_TODO_

## ğŸª£ Allow Relocating Backup Buckets

_TODO_

## ğŸª Pull `gardener-node-agent` From Registry Mirror

_TODO_

## ğŸ—½ Evaluate [Talos](https://www.talos.dev/) As Node Operating System

_TODO_

## ğŸ“¦ Gardener API Types As Standalone Go Module

_TODO_

## ğŸ“ˆ Gardener Scale-Out Tests

_TODO_

## â¤ï¸â€ğŸ©¹ `force-restore` Operation Annotation For `Shoot`s

_TODO_

## ğŸ—ƒï¸ Go Build Cache In Prow

[Shafeeque](https://github.com/shafeeqes) and [Tobias](https://github.com/shegox) explored the build and test caching for [Gardener Prow](https://prow.gardener.cloud/) jobs.
During this process, we discovered some interesting aspects of how Go caching works, its usage, and how the new Go feature [`GOCACHEPROG`](https://pkg.go.dev/cmd/go/internal/cacheprog) operates.

We pursued three goals:

1. Speed up time-to-feedback on pull requests.
2. Reduce load on the Prow build clusters.
3. Do this securely.

For security, it was critical that presubmit (pull request) jobs could read from the cache but never write to it.
This prevents untrusted PRs and potentially broken jobs from polluting the cache.

We first reviewed how other projects handle caching:

- **Istio:** Uses a [hostPath volume](https://github.com/istio/test-infra/blob/c739e67b9aa67b0ffec6917a49f5e235e1fe0872/prow/cluster/jobs/istio/istio/istio.istio.master.gen.yaml#L38-L51) to reuse cache on the same node. This helps somewhat, but suffers from numerous cache misses as jobs are assigned to different nodes. With our autoscaling worker groups, node churn would make misses even more common, so this wouldnâ€™t be effective for us.
- **Kubermatic machine-controller:** Uses scripts to [fetch a cache archive](https://github.com/kubermatic/machine-controller/blob/345eaa102974eda999b6cc59c9e21116b4e81e8e/hack/ci/download-gocache.sh) for the PR's ancestor commit from blob storage before the build, and [upload an updated cache](https://github.com/kubermatic/machine-controller/blob/345eaa102974eda999b6cc59c9e21116b4e81e8e/hack/ci/upload-gocache.sh) on main after the build. This mirrors systems like GitHub Actionsâ€™ actions/cache and works with plain file systems, so build tooling doesnâ€™t need remote cache awareness.

We considered using a ReadWriteMany persistent volume for caching to achieve a similar setup to Istio, but across multiple nodes.
On GCP, the practical option is NFS Filestore, which is quite expensive.
Additionally, to make presubmits read-only, weâ€™d have to copy the cache to a local directory before buildsâ€”an expensive step for large caches that erodes the performance benefits.

Go recently introduced the `GOCACHEPROG` feature, which allows you to plug in a custom program to read from and write to the build and test cache.
We're using it with the open-source [`saracen/gobuildcache`](https://github.com/saracen/gobuildcache) to store cache entries in Google Cloud Storage.

- This gives us a "remote cache helper" without needing to download/upload an entire cache directory before/after each build.
- Because Goâ€™s cache is highly granular (per compiled/tested unit), we only fetch what's needed rather than relying on commit ancestry heuristics.
- Google Cloud Storage doesn't charge network costs within the same region and only minimal costs for storage and operations.
- Trade-off: many small requests to the remote backend are slower than local filesystem access. However, with our high hit rate, the overall impact is very positive.

We use separate GCP principals, federated from the Prow shoot cluster via Workload Identity Federation, with read-only permissions for presubmit jobs and read-write permissions for postsubmit and periodic jobs.

With this setup, we have already significantly accelerated builds.
However, some parts, like `go test` and linting, didnâ€™t speed up as much.
We found that `go test` only caches results when a limited set of flags is used; in Prow, we rely on `ginkgo.junit-report=junit.xml` to produce JUnit reports for pull requests, and this flag disables test result caching.
In local experiments, removing this flag enabled caching and dramatically reduced unit test time (for example, from approximately 40 minutes to under 5 minutes).

Overall, weâ€™re happy with the first improvements.
Examining Gardenerâ€™s jobs, we did not significantly reduce end-to-end feedback time for presubmits; however, the actual CPU time spent on builds decreased by more than 90%.
The impact is particularly clear in the kind-e2e tests: they used to take roughly 1 hour 30 minutes and consume about 65 minutes of CPU time across 12 cores in parallel at the beginning; now they consume under 3 minutes of CPU time across fewer than 2 cores.
This substantially reduces the load on the build cluster.

### kind e2e tests without cache

```terminaloutput
real        85m20.914s
user        64m51.059s
sys          6m42.249s
```

![Prow CPU metrics without cache showing 12 CPUs being used during build](images/2025-11/prow-go-build-cache/prow-without-cache.png)

### kind e2e tests with cache

```terminaloutput
real        82m53.159s
user         2m33.118s
sys          1m0.021s
```

![Prow CPU metrics with cache showing 2 CPUs being used during build](images/2025-11/prow-go-build-cache/prow-with-cache.png)

## ğŸ› ï¸ MCM: Update Machines Updates During In-Place Updates

_TODO_

## ğŸ”” `gardenadm`/Flow Package: Handle `SIGINFO` (`^T`)

_TODO_

## âš–ï¸ï¸ Load Balancer Controller For `provider-local`

_TODO_

## ğŸ”Œ Evaluation Of NFT Mode In `kube-proxy`

_TODO_

## ğŸŒ‰ Replace Ingress NGINX controller With Gateway API

_TODO_

## ğŸ± Add Support For Calico Whisker

_TODO_

## ğŸ·ï¸ Respect Terminating `Node`s In Load-Balancing

_TODO_

## ğŸ§° Use Go Tools & Drop `VGOPATH`

_TODO_

## ğŸ”€ Pod Overlay To Native Routing Without Downtime

_TODO_

## ğŸšª [GEP-28] Expose API server Of Self-Hosted Shoots

_TODO_

## ğŸ¤– Tool-Enabled Agent For Shoots

_TODO_

---

![ApeiroRA](https://apeirora.eu/assets/img/BMWK-EU.png)
